{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from keras.layers import Input, TimeDistributed, Lambda, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import scipy.io\n",
    "from copy import deepcopy\n",
    "import tqdm \n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "sys.path.append('./src')\n",
    "tf.compat.v1.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "os.environ['PYTHONHASHSEED'] = str(1234)\n",
    "\n",
    "from data_loading import load_datasets_singleduration\n",
    "from util import get_model_by_name, create_losses\n",
    "from losses_keras2 import kl_cc_combined, kl_cc_nss_combined, kl_cc_nss_combined_new\n",
    "\n",
    "from sal_imp_utilities import *\n",
    "from cb import InteractivePlot\n",
    "from losses_keras2 import loss_wrapper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n",
    "\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames_ours = glob.glob('./images/*g')\n",
    "imp_filenames_ours = glob.glob('./saliency_gt/*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_filenames_ours), len(imp_filenames_ours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THESE IN: set training parameters \n",
    "ckpt_savedir = \"ckpt\"\n",
    "\n",
    "load_weights = False\n",
    "weightspath = \"\"\n",
    "\n",
    "batch_size = 4\n",
    "init_lr = 0.0001\n",
    "lr_reduce_by = .1\n",
    "reduce_at_epoch = 3\n",
    "n_epochs = 50\n",
    "\n",
    "opt = Adam(lr=init_lr) \n",
    "\n",
    "# losses is a dictionary mapping loss names to weights \n",
    "losses = {\n",
    "    'kl': 10,\n",
    "    'cc': -3,\n",
    "}\n",
    "\n",
    "model_name = \"UMSI\"\n",
    "\n",
    "model_inp_size = (256, 256)\n",
    "model_out_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model \n",
    "model_params = {\n",
    "    'input_shape': model_inp_size + (3,),\n",
    "    'n_outs': len(losses),\n",
    "}\n",
    "model_func, mode = get_model_by_name(model_name)\n",
    "assert mode == \"simple\"\n",
    "model = model_func(**model_params)\n",
    "\n",
    "if load_weights: \n",
    "    model.load_weights(weightspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up data generation and checkpoints\n",
    "if not os.path.exists(ckpt_savedir): \n",
    "    os.makedirs(ckpt_savedir)\n",
    "    \n",
    "# sort the losses so that those that use a fixmap are last, by convention\n",
    "l, lw, l_str, n_heatmaps = create_losses(losses, model_out_size)\n",
    "n_fixmaps = len(l) - n_heatmaps\n",
    "print(\"Loss string\", l_str)\n",
    "    \n",
    "# Generators\n",
    "gen_train = ImpAndClassifGenerator(\n",
    "        img_filenames=img_filenames_ours,\n",
    "        imp_filenames=imp_filenames_ours,\n",
    "        fix_filenames=None,\n",
    "        extra_fixs=None,\n",
    "        extras_per_epoch=160,\n",
    "        batch_size=4,\n",
    "        img_size=(shape_r,shape_c),\n",
    "        map_size=(shape_r_out, shape_c_out),\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        n_output_maps=1,\n",
    "        concat_fix_and_maps=False,\n",
    "        fix_as_mat=False,\n",
    "        fix_key=\"\",\n",
    "        str2label=None,\n",
    "        dummy_labels=False,\n",
    "        num_classes=6,\n",
    "        pad_imgs=True,\n",
    "        pad_maps=True,\n",
    "        return_names=False,\n",
    "        return_labels=True,\n",
    "        read_npy=False)\n",
    "\n",
    "# where to save checkpoints\n",
    "filepath = os.path.join(ckpt_savedir, \"umsi++_\" + l_str + '_ep{epoch:02d}_valloss{loss:.4f}.hdf5')\n",
    "print(\"Checkpoints will be saved with format %s\" % filepath)\n",
    "\n",
    "cb_chk = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, period=1)\n",
    "cb_plot = InteractivePlot()\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = init_lr * math.pow(lr_reduce_by, math.floor((1+epoch)/reduce_at_epoch))\n",
    "    if epoch%reduce_at_epoch:\n",
    "        print('Reducing lr. New lr is:', lrate)\n",
    "    return lrate\n",
    "cb_sched = LearningRateScheduler(step_decay)\n",
    "\n",
    "cbs = [cb_chk, cb_sched, cb_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, outs = gen_train.__getitem__(1)\n",
    "print(\"batch size: %d. Num inputs: %d. Num outputs: %d.\" % (batch_size, len(img), len(outs)))\n",
    "preds = model.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = \"./weights/umsi++.hdf5\"\n",
    "model.load_weights(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames_ours_test = glob.glob('./images/*g')\n",
    "imp_filenames_ours_test = glob.glob('./saliency_gt/*g')\n",
    "len(img_filenames_ours_test), len(imp_filenames_ours_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some output on the val set \n",
    "gen = UMSI_eval_generator(\n",
    "    img_filenames_ours_test, \n",
    "    imp_filenames_ours_test, \n",
    "    inp_size=model_inp_size)\n",
    "\n",
    "examples = [next(gen) for _ in range(len(img_filenames_ours_test))]\n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the testing data\n",
    "for example in examples:\n",
    "    \n",
    "    # show the original image\n",
    "    images, maps, img_filename_= example\n",
    "    preds = model.predict(images[0])\n",
    "    preds_map = preds[0]\n",
    "    preds_classif = preds[1]\n",
    "    print(\"maps size\", len(maps), maps[0].shape)\n",
    "    batch = 0\n",
    "    plt.gray()\n",
    "    plt.figure(figsize = (14,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "    plt.title(\"natural images %d\" % batch)\n",
    "    \n",
    "    # show the ground truth heatmap\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(maps[0])\n",
    "    plt.title('Gt ' )\n",
    "    \n",
    "    # show the predicted heatmap\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    pred_result = postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], normalize=False, zero_to_255=True)\n",
    "    plt.imshow(pred_result)\n",
    "    plt.title('Prediction')\n",
    "    # uncomment to save to the folder save_dir\n",
    "    # save_dir = ''\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "    # plt.imsave(save_dir + img_filename_.split('/')[-1], pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umsipp",
   "language": "python",
   "name": "umsipp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
